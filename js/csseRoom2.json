{
    "csse": [
        {
            "time": "1:00 PM - 1:15 PM",
            "projectId": "csse-2-100",
            "title": "SRE AI Chatbot-Software Engineering Internship at Avanade",
            "studentName": "Lucy Citrisky",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship or job opportunity ",
            "facultyAdvisor": "Dr. Afra Mashhadi",
            "posterLink": "./posters/csse/citriskylucy_4202295_113477850_Citrisky,Lucy_Poster.jpg",
            "abstract": "At the start of my intern project at Avanade, I was introduced to a problem that many SREs (Site Reliability Engineers) are facing: their workload is becoming increasingly higher as customers shift their IT services to the cloud, causing new problems to arise. My team’s end goal was to ease SRE’s efforts in solving these issues by providing a tool that would sift through knowledge bases, GitHub repositories, and various websites for them. To accomplish this, we created Rockstar, an OpenAI-powered chatbot that was integrated into Microsoft Teams and specially trained in Site Reliability Engineering. At any time, the user within the Teams channel could tag the bot and ask it a question about site reliability; the bot would answer using any relevant information from SRE documents that the user had provided.\n\n My task was to build the brains behind the bot, making sure it met specific requirements such as answering only relevant questions and using the provided internal documents. After deploying an OpenAI gpt-35-turbo model within Azure AI Studio, I was able to make API calls from Microsoft Power Automate to retrieve responses from the model.\n\n While building this out, the main goal I worked on was prompt-engineering the model to act as an SRE expert. I accomplished this by testing how different prompts performed, passing them in JSON files to the API until the model was able to effectively pull information from a set of internal company files and answer from the perspective of an SRE. If it could not find an answer using the internal documents, it was instructed to provide an answer from the internet. During this process, I made the internal files available to the model by using Power Automate to translate the documents into a string format and deliver them to the model via JSON files.\n\n Throughout the project, I collaborated with my team members to brainstorm different solutions and overcome any roadblocks we ran into. The final product, our Rockstar chatbot, reached our requirements and was able to quickly respond to SRE-related issues using internal documents and assist SREs in reaching 100% infrastructure availability.\n\n During my time at Avanade, I gained knowledge on modern industry practices, effective communication in a team, and worked within an Agile workflow. I was proud of my team for taking an idea from start to finish, packaging it as a final product, and presenting it to executives. "
        },
        {
            "time": "1:15 PM - 1:30 PM",
            "projectId": "csse-2-115",
            "title": "Trusted Firmware A-profile (TFA)",
            "studentName": "Thaddeus Gonzalez-Serna",
            "studentMajor": "CSSE",
            "projectType": "",
            "facultyAdvisor": "Dr. Afra Mashhadi",
            "posterLink": "./posters/csse/gonzalezSerna_thaddeus.png",
            "abstract": ""
        },
        {
            "time": "1:30 PM - 1:45 PM",
            "projectId": "csse-2-130",
            "title": "Migrating A Legacy System Onto The Cloud ",
            "studentName": "Ryan Leveck ",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship or job opportunity ",
            "facultyAdvisor": "Dr. Afra Mashhadi",
            "posterLink": "./posters/csse/levecksteven_4029497_113252551_Leveck_Capstone_Poster.jpg",
            "abstract": " My capstone encompasses my internship at Mutual of Enumclaw, an insurance company founded in Enumclaw Washington. The team I worked with, known as the Nucleus Team, had been tasked with migrating Mutual’s former legacy system onto the cloud. Previously, this legacy system centered around batch processing which placed limitations on their ability to process and alter policy transactions. By migrating to the cloud, they’ll be able to make real-time changes to all transactions, improve customer support, and increase savings.\n\n The preliminary work I was introduced to centered around fixing bugs that had either been discovered in their internal UI or flagged by Sonar Cloud. In doing so, I was first introduced to both pair programming and test-driven development. While working alongside my coworkers, I was also instructed on how to develop unit tests for the specific lambda functions these bug fixes belonged to.\n\n The next portion of work I was tasked with dealt with the deployment of all Nucleus-based repositories to new AWS Sandbox accounts. In total, there were twenty-eight repositories that needed to be deployed, giving me an introduction to various AWS services. The main elements to this work involved establishing new environments on GitHub for each repository, altering infrastructure code to reflect specified conventions, and migrating SSM parameters to the new Sandbox accounts.\n\n The final project I worked on dealt with a state-specific procedure that would allow for the ordering of credit scores to help determine insurance ratings. My role involved the development of four of the five necessary lambda functions this project called for. Working alongside coworkers, our jobs ranged from extracting data, merging files, parsing files, updating policies, and communicating with various AWS services and third-party vendors.\n\n Throughout my time at Mutual I was able to gain a lot of great experience as a software engineering intern and participate in several industry dynamics I had learned about in school. These efforts led to increased validation of their internal UI which will positively impact several teams working within Mutual. The foundation laid for the repository deployment served as an important step forward in the overall migration process. And the progress made on the credit score project allowed Nucleus to stay on track for their deployment in October 2023. "
        },
        {
            "time": "1:45 PM - 2:00 PM",
            "projectId": "csse-2-145",
            "title": "Software Development Intern for T-Mobile ",
            "studentName": "Bastien Orbigo",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship or job opportunity ",
            "facultyAdvisor": "Dr. Afra Mashhadi",
            "posterLink": "./posters/csse/orbigobastienalan_3975952_113442930_Capstone Poster.png",
            "abstract": "This capstone was an internship as a Software Development Intern for T-Mobile within the Enterprise Technology Solutions (ETS) department, specifically the Platform Delivery & Automation (PDA) team. The PDA team has developed an internal-use application, Narwhal, through which all application teams are able to view their designated quota, receive aid in managing proper sizing, manage build configurations, and address all server/application related items. \n\n One problem, however, was that teams lacked a designated space to find their quota, monitor their current usage, or explore Metal-as-a-Service (MaaS) configurations, before onboarding. This produced a prolonged process for teams, as they had to manually view their builds, track and compute their usage or maneuver the lengthy onboarding to MaaS before even viewing configurations. Additionally, MaaS admins were also without a similar space, resulting in occasions where teams needed to see their quota and usage. In this scenario, MaaS admins would often be the ones responsible for the multi-hour process of calculating and filtering through current configurations.\n\n To address this need, my capstone project focused on developing a space for application teams and MaaS admins to conduct these functionalities, streamlining reservations and reducing the time necessary by significant margins. My responsibility was the following: \n1) Develop a space for application teams to view the MaaS configurations, allowing them to view details such as the type of hardware, basic specs, overall usage, and the different datacenters, environments, and/or availability zones in use. \n 2) Develop a space specific to application teams in which they can view their current usage, their overall quota including the number of that hardware that is reserved, deployed, and available, and similarly, the different datacenters, environments, and/or availability zones in use.\n\n\n Over the course of 12 weeks, the development of these services has been completed, benefiting all T-Mobile application teams onboarded to MaaS, with the capability of expansion to different cloud types such as VMware in the future. This expansion will help reduce back-and-forth communication between MaaS admins and end users, promoting self-service for application teams. Finally, this will help increase visibility for Capacity Management Teams, greatly improve convenience for MaaS admins, and benefit all development teams. "
        },
        {
            "time": "2:00 PM - 2:15 PM",
            "projectId": "csse-2-200",
            "title": "Interactive Data Visualizations: Enhancing Data Literacy and Insights",
            "studentName": "Skyla Tran",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship or job opportunity ",
            "facultyAdvisor": "Dr. Afra Mashhadi",
            "posterLink": "./posters/csse/transkyla_4102147_113215116_poster_SkylaTran-2.png",
            "abstract": "The Marine Exchange of Puget Sound (MAREXPS) is a non-profit organization dedicated to supporting the maritime community’s goals with real-time, vessel tracking data and organizational support services. MAREXPS aims to improve, strengthen, and provide impactful information/tools to the maritime community through daily/monthly reports, AIS vessel tracking, community-based new letters, and more. \n\n During my internship, I focused on the data and technology domain of the company. Although MAREXPS collects decades' worth of data, this information has never been presented in a way other than number-packed reports and Excel workbooks. My primary responsibility during this internship was to spearhead the development and design of a new, more intuitive, and accessible tool for analyzing data insights. I specifically worked on creating interactive dashboards and streamlining/optimizing the monthly updating process of datasets. \n\n I used software like Tableau (Cloud, Public, and Builder Prep), RAWGraphs 2.0, Mapbox, and Microsoft/Adobe Suites to create these dashboards. I was also exposed to ArcGIS software and usages although not included in the dashboards themselves. \n\n Throughout development, I followed UCD (user-centred design) methodology and agile development models to create a product that is both desirable and useful for the target audience. Organizations such as the Washington State Department of Ecology, Port of Seattle/Tacoma/Everett, United States Coast Guard, and others are included in the audience who work with this information daily and will benefit from this new tool. \n\n These interactive dashboards can assist members of the maritime community in enhancing their decision-making processes, managing their day-to-day business operations, presenting credible and accurate reports, and ultimately improving overall data literacy and quality of life regarding analysis within the maritime community. "
        },
        {
            "time": "2:15 PM - 2:30 PM",
            "projectId": "csse-2-215",
            "title": "Polyglot Go – Bridging Language Barriers Through Innovation",
            "studentName": "Nguyen Vi Cao",
            "studentMajor": "CSSE",
            "projectType": "Group Project",
            "facultyAdvisor": "Dr. Min Chen ",
            "posterLink": "./posters/csse/caonguyenvi_LATE_4145244_113494237_CSS 497 Capstone Poster (1).png",
            "abstract": "For our capstone, we were working in a group of two to create a language learning app called “Polyglot Go” which run on platform such as desktop, iPad, and iPhone.\n\n In a world increasingly defined by linguistic diversity, language barrier has become a main issue for everyone especially for the newly transferred or admitted students. Due to this, learning new languages, cultures, and making new friends have emerged as a real challenge. However, this should not present an obstacle to prevent one’s passion; we believe learning new language and cultures should be fun and simple. This would be the core objective for our project, which is to make the learning process easier and more enjoyable.\n\n In crafting our application, we did various research on finding a more efficient way to write and manage our code files. Our strategic choice was made to employ “FlutterFlow” as the main development environment. The choice stems from the uniqueness of the platform to seamlessly meld visual design (Front end) with underlying Dart code (Backend), resulting in dynamic and responsive user interfaces. Moreover, FlutterFlow gave us the ability to create complex widgets, tools, deploy APIs and interactions that can simulate real-world language usage scenarios (such as our flashcard’s flipping card widget, etc.)\n\n Overall, we utilized FlutterFlow to create 3 different learning types such as Flashcard, wordmatching and Translation; and each learning type supports three different languages such as Chinese (Mandarin), Vietnamese and Khmer (Cambodian). On top of that, we created basic login (sign up) page, home page (language selection), progress page, goal page, etc. Furthermore, it is noteworthy to mention that we used Google Firebase service as our main database to store our user information and language data pack.\n\n In summary, “Polyglot Go” represents the fusion of innovative technology and creative teaching ideas, offering a more enjoyable approach to language learning. By making language learning fun and easy, we contribute to breaking down barriers and fostering meaningful connections among diverse communities. "
        },
        {
            "time": "2:30 PM - 2:45 PM",
            "projectId": "csse-2-230",
            "title": "Software Development for a Job Board",
            "studentName": "Shu-Ling Lin",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship or job opportunity ",
            "facultyAdvisor": "Dr. Min Chen ",
            "posterLink": "./posters/csse/linshuling_3935478_113464476_poster.png",
            "abstract": "I worked as a software engineering intern at FutureForte during this summer. I was able to gain practical knowledge of full-stack development and contribute to the design and development of the Job Board project. Since FutureForte is a fast-paced startup company, I had the opportunity to work closely with the team and acquire an in-depth understanding of the company products through optimizing user experience, conducting market research to identify industry trends, and assisting in content creation for job listings.\n\n I started by creating two simple projects in Node.js and React.js and deploying them to AWS Amplify and Elastic Beanstalk. Next, I got myself familiarized with Tailwind CSS, which was one of the main tools for my project. As I had a better grasp of the tools, I began developing the job board by reading data from JSON files and applying Tailwind UI components. In the first few weeks, whenever I got stuck on the tasks, I would consult online resources and my mentor for help. I found it extremely helpful to document my progress and the challenges I faced.\n\n For the second half of my internship, I focused on optimizing the company's website and customized a dashboard for potential customers. I created user stories for universities by incorporating the knowledge learned in the User-Centered Design class and conducting market research. I also generated data to display on the dashboard and added more menu options. With ample web development experience at that point, I tailored the company's website based on industry trends and analysis.\n\n I was beyond grateful to have the opportunity to intern at FutureForte. It was my first time working in a startup environment. It could be stressful sometimes but also allowed me to grow and acquire new skills in a short period. "
        },
        {
            "time": "2:45 PM - 3:00 PM",
            "projectId": "csse-2-245",
            "title": "Youtuber Personality Imitation using Machine Learning",
            "studentName": "Ellsworth McCullough",
            "studentMajor": "CSSE",
            "projectType": "Individual Project",
            "facultyAdvisor": "Dr. Min Chen ",
            "posterLink": "./posters/csse/mcculloughellsworth_LATE_4029913_113534411_YPIML Poster Ellsworth McCullough.png",
            "abstract": "For this capstone project, a program was created that used large language models (LLMs) to imitate numerous YouTubers’ personalities. The program also streamlined the process of fine-tuning a model to a given YouTuber’s personality. The motivation for this project stemmed from an interest in learning more about LLMS and full-stack software development.\n\n The project was separated into four main parts: data collection, data processing, model training, and model usage. Concerning data collection, it was done using the YouTube Data API, the simplest and most reliable tool to get the information required. The data that was collected was first the list of videos for a YouTuber, which were combed through to find ones suitable to be trained off of, and then the transcripts for those videos were pulled and later processed.\n\n For the processing of the transcripts, the first step was to strip the transcripts of all information that was not pure text and separate that text into chunks, followed by generating example prompts and using a combination of ChatGPT/Relevance AI to extrapolate from those example prompts to generate prompts to cover the rest of the text chunks. The reason for using tools like ChatGPT was that it seemed a more feasible option than manually writing thousands of prompts.\n\n After this, model training would start. The model that was fine-tuned was Falcon-7B, an open-source model that performs better than its competitors while being able to be run on personal machines. I fine-tuned the model in Google Colab and used numerous tools from the Hugging Face library to help in training the model, focusing on having the generated models be able to respond to both personal questions and questions related to their videos. For the model usage, I created a GUI using Python’s Tkinter that allows the user to select a trained model for a YouTuber, prompt said model, and export that exchange for later usage.\n\n In conclusion, I developed a project capable of at least partially imitating a YouTuber’s personality. Throughout the process, I learned how to use numerous industry-relevant tools and gained experience in refactoring and writing maintainable code. "
        },
        {
            "time": "3:00 PM - 3:15 PM",
            "projectId": "csse-2-300",
            "title": "Software Engineering Internship at Data I/O",
            "studentName": "Matthew Okot-Okidi",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship or job opportunity ",
            "facultyAdvisor": "Dr. Min Chen ",
            "posterLink": "./posters/csse/okotokidimatthew_3961036_113478810_Matthew Okot-Okidi Capstone Poster.jpg",
            "abstract": "I worked on three projects during my internship at Data I/O. Data I/O makes manual and automatic device programmers. The first project was reimplementing C# and XAML database migration code in our device programmer management software to switch to using Entity Framework Core instead of pure C# and SQL.\n\n This project made the code easier to maintain. The company originally used pure C# and SQL because the codebase was less complex. While working on the database code, I also removed code that was no longer used and fixed a bug that would cause the device management software to shut down if a database didn’t exist. This improved developer velocity and made it easier for our customers to use their devices.\n\n The second project was to optimize the list of programmer jobs in the device management software using C# and XAML. Customers and our company’s engineers noticed that the list would take a long time to load when there were hundreds of jobs or large jobs. \n\n My solution was to prevent jobs from being cached when the program started and to only fully load the job when it was about to be run. This saved engineers and customers a lot of time when running jobs. \n\n The third project was to create a tool for automating the generation of test files. This was needed because our engineers had to manually create test files by writing a script or using a customer’s file. \n\n I designed and implemented a command line application using C# that could create a variety of different types of data. This saved our company’s engineers a lot of time when testing new features. "
        }
    ]
}